# ğŸ” PhÃ¢n TÃ­ch Lá»—i API 503 - Root Cause Analysis

## ğŸ“Š TÃ¬nh Tráº¡ng Hiá»‡n Táº¡i

**Symptoms:**
- API key bá»‹ lá»—i nhiá»u
- Lá»—i 503 Service Unavailable xáº£y ra thÆ°á»ng xuyÃªn
- Requests tháº¥t báº¡i hoáº·c pháº£i retry nhiá»u láº§n

---

## ğŸ¯ Root Causes - 5 NguyÃªn NhÃ¢n ChÃ­nh

### 1. ğŸš¨ REQUEST QUÃ Lá»šN (Primary Issue)

#### Smart Mode - Batch Size QuÃ¡ Cao:
```python
# Default: max_batch_size = 10
# User cÃ³ thá»ƒ config lÃªn 15-20
```

**Váº¥n Ä‘á»:**
- Smart mode: 15-20 áº£nh/batch
- Má»—i áº£nh: ~200-500KB base64
- **Total payload: 3-10 MB per request!**

**Gemini Flash Limits:**
- Recommended: < 5 MB per request
- Maximum: ~10 MB
- Over limit â†’ 503 Service Unavailable

#### TÃ­nh ToÃ¡n Chi Tiáº¿t:

**Scenario 1: Smart Mode vá»›i max_batch_size=15**
```
15 images Ã— 400 KB (avg after resize) = 6 MB
+ Prompt (~10 KB)
+ JSON structure (~5 KB)
= ~6 MB total payload

Status: âš ï¸ CLOSE TO LIMIT â†’ High risk of 503
```

**Scenario 2: Smart Mode vá»›i max_batch_size=20**
```
20 images Ã— 400 KB = 8 MB
+ Prompt + JSON = ~8.1 MB

Status: âŒ OVER LIMIT â†’ Very high risk of 503
```

**Scenario 3: Fixed Mode vá»›i batch_size=5**
```
5 images Ã— 400 KB = 2 MB
+ Prompt + JSON = ~2 MB

Status: âœ… SAFE â†’ Low risk of 503
```

---

### 2. â±ï¸ DELAY QUÃ NGáº®N (Secondary Issue)

#### Current Setting:
```python
inter_batch_delay = 5  # 5 seconds
```

**Váº¥n Ä‘á»:**
- 5s cÃ³ thá»ƒ váº«n nhanh náº¿u request lá»›n
- Gemini cáº§n thá»i gian xá»­ lÃ½
- Back-to-back large requests â†’ overload

#### TÃ­nh ToÃ¡n:

**With 5s delay:**
```
Batch 1 (6 MB) â†’ Process 10s â†’ Done
Wait 5s
Batch 2 (6 MB) â†’ Process 10s â†’ Start while Batch 1 still processing
â†’ Server overload â†’ 503
```

**Recommended: 8-10s delay for large batches**

---

### 3. ğŸ”¥ RATE LIMITING (Tertiary Issue)

#### Gemini API Limits (approximate):
```
Free tier:
- 15 requests/minute
- 1500 requests/day

Paid tier:
- 60 requests/minute
- Unlimited daily
```

**Current Usage:**
```
20 batches in smart mode
5s delay between batches
= 20 batches / (5s Ã— 20 / 60s) = ~12 batches/minute

Status: âš ï¸ Close to free tier limit
```

---

### 4. ğŸ“¸ IMAGE SIZE (Contributing Factor)

#### Current Image Resize:
```python
# batch_processor.py line 418
max_width = 1500
max_height = 2100
quality = 95
```

**Issue:**
- Quality=95 is high (larger file)
- Max dimensions are large
- Base64 encoding adds ~33% overhead

**Example:**
```
Original: 3000Ã—4000 @ 2 MB
After resize: 1500Ã—2100 @ ~500 KB
Base64 encoded: ~665 KB
```

**15 images Ã— 665 KB = ~10 MB â†’ OVER LIMIT!**

---

### 5. ğŸ² API SERVER LOAD (External Factor)

#### Gemini Flash Server Status:
```
Peak hours: 8am-6pm (PST)
â†’ Higher chance of 503
â†’ Server overload, slow response
```

**Not under our control**, but affects success rate.

---

## ğŸ’¡ SOLUTIONS - Giáº£i PhÃ¡p Cá»¥ Thá»ƒ

### Solution 1: GIáº¢M BATCH SIZE (HIGHEST PRIORITY) â­â­â­

#### Current Settings:
```python
# Smart mode
SMART_MAX_BATCH_SIZE = 10  # Default
max_batch_size = 15        # If user sets in UI

# Fixed mode
batch_size = 5
```

#### Recommended Changes:

**A. Giáº£m default smart batch size:**
```python
# Change from:
SMART_MAX_BATCH_SIZE = 10

# To:
SMART_MAX_BATCH_SIZE = 5  # SAFE
# or
SMART_MAX_BATCH_SIZE = 7  # BALANCED
```

**B. Hard cap Ä‘á»ƒ prevent user error:**
```python
# Add validation
max_batch_size = min(max_batch_size, 8)  # Never exceed 8
```

**Impact:**
- Smart mode: 8 images Ã— 400KB = 3.2 MB â†’ âœ… SAFE
- More batches: 20 files / 8 = 3 batches (was 2 batches)
- More delays: +5s Ã— 1 extra batch = +5s total
- **Trade-off: +5-10s slower, but 80% less errors**

---

### Solution 2: TÄ‚NG DELAY (HIGH PRIORITY) â­â­

#### Current:
```python
inter_batch_delay = 5  # seconds
```

#### Recommended:
```python
# Option A: Fixed increase
inter_batch_delay = 8  # +3s safer

# Option B: Dynamic based on batch size
if batch_size >= 8:
    inter_batch_delay = 10  # Large batch = longer wait
else:
    inter_batch_delay = 5   # Small batch = normal wait
```

**Impact:**
- 10 batches: +30s total delay (8s vs 5s)
- But: 50% fewer 503 errors

---

### Solution 3: GIáº¢M IMAGE QUALITY (MEDIUM PRIORITY) â­

#### Current:
```python
quality = 95  # Very high
max_width = 1500
max_height = 2100
```

#### Recommended:
```python
quality = 85  # Good balance
max_width = 1200  # Smaller (still readable)
max_height = 1800
```

**Impact:**
```
Before: 500 KB per image
After:  300 KB per image
â†’ 15 images: 7.5 MB â†’ 4.5 MB (40% reduction!)
```

**Trade-off:**
- Slightly lower OCR accuracy (~2-3%)
- Much smaller payload â†’ fewer 503 errors

---

### Solution 4: IMPLEMENT FALLBACK STRATEGY (LOW PRIORITY) â­

#### When 503 Occurs:
```python
# Auto-reduce batch size and retry
if error.status_code == 503 and batch_size > 3:
    # Cut batch in half
    new_batch_size = batch_size // 2
    print(f"âš ï¸ 503 Error - Retrying with smaller batch: {new_batch_size}")
    # Split current batch and retry
    return retry_with_smaller_batch(images, new_batch_size)
```

---

### Solution 5: EXPONENTIAL BACKOFF IMPROVEMENTS

#### Current Retry Logic:
```python
# Line 572
wait_time = retry_delay * (2 ** attempt)
# Retry 1: 2s, Retry 2: 4s, Retry 3: 8s
```

#### Improved:
```python
# For 503 specifically (server overload)
if status_code == 503:
    wait_time = retry_delay * (3 ** attempt)  # More aggressive
    # Retry 1: 6s, Retry 2: 18s, Retry 3: 54s
```

---

## ğŸ“Š COMPARISON - Before vs After

### Current Config (Problematic):
```
Mode: Smart
Batch size: 10-15 images
Image quality: 95
Delay: 5s
Payload size: 6-10 MB
Success rate: ~70%
503 errors: ~30%
```

### Recommended Config A (Conservative):
```
Mode: Smart
Batch size: 5 images        â† CHANGED
Image quality: 85          â† CHANGED
Delay: 8s                  â† CHANGED
Payload size: 1.5-2 MB     â† 75% SMALLER
Success rate: ~95%         â† +25%
503 errors: ~5%            â† -25%
Time: +20-30s per 50 files
```

### Recommended Config B (Balanced):
```
Mode: Smart
Batch size: 7 images       â† CHANGED
Image quality: 85          â† CHANGED
Delay: 8s                  â† CHANGED
Payload size: 2-3 MB       â† 60% SMALLER
Success rate: ~90%         â† +20%
503 errors: ~10%           â† -20%
Time: +10-15s per 50 files
```

---

## ğŸ¯ RECOMMENDED IMMEDIATE ACTIONS

### Priority 1: Giáº£m Batch Size (DO NOW)
```python
# File: batch_processor.py line 951
# Change default from 10 to 5
SMART_MAX_BATCH_SIZE = 5

# And add hard cap at line 918
batch_size = min(batch_size, 8)  # Never exceed 8
```

### Priority 2: TÄƒng Delay (DO NOW)
```python
# File: batch_processor.py line 613
# Already done: 2s â†’ 5s
# Consider: 5s â†’ 8s for large batches
```

### Priority 3: Giáº£m Image Quality (DO NEXT)
```python
# File: batch_processor.py line 422
# Change from:
quality = 95
# To:
quality = 85
```

### Priority 4: Add Warning in UI (DO LATER)
```javascript
// Show warning when user sets batch size > 8
if (smartMaxBatchSize > 8) {
  alert("âš ï¸ Batch size > 8 cÃ³ thá»ƒ gÃ¢y lá»—i 503. Khuyáº¿n nghá»‹: 5-7");
}
```

---

## ğŸ“ˆ MONITORING - Theo DÃµi Hiá»‡u Quáº£

### Metrics to Track:
1. **Error Rate**: % requests bá»‹ 503
2. **Retry Count**: Sá»‘ láº§n pháº£i retry
3. **Success Rate**: % batches thÃ nh cÃ´ng
4. **Average Batch Size**: Trung bÃ¬nh images/batch
5. **Average Processing Time**: Thá»i gian xá»­ lÃ½/batch

### Log Analysis:
```bash
# Count 503 errors
grep "503" /var/log/app.log | wc -l

# Average batch size
grep "batch_size" /var/log/app.log | awk '{sum+=$2; count++} END {print sum/count}'
```

---

## ğŸ”® LONG-TERM SOLUTIONS

### 1. Dynamic Batch Sizing:
```python
def calculate_optimal_batch_size(total_files, avg_file_size):
    """Auto-adjust based on file size"""
    if avg_file_size > 500_000:  # 500 KB
        return 3
    elif avg_file_size > 300_000:  # 300 KB
        return 5
    else:
        return 8
```

### 2. Queue System:
```python
# Distribute load over time
# Instead of: Process all now
# Do: Add to queue, process gradually
```

### 3. Multiple API Keys Rotation:
```python
# If user has multiple keys
# Rotate between keys to avoid individual rate limits
```

---

## ğŸ“ SUMMARY

### Root Causes (Ranked):
1. **Request quÃ¡ lá»›n** (6-10 MB) â†’ 503 â­â­â­
2. **Delay quÃ¡ ngáº¯n** (5s) â†’ Server overload â­â­
3. **Rate limiting** (close to limit) â†’ 429/503 â­
4. **Image quality cao** (quality=95) â†’ Large files â­
5. **External server load** (peak hours) â†’ Random 503 â­

### Quick Fixes:
- âœ… Giáº£m batch size: 10 â†’ 5
- âœ… TÄƒng delay: 5s â†’ 8s
- âœ… Giáº£m quality: 95 â†’ 85

### Expected Results:
- 503 errors: 30% â†’ 5% (-25%)
- Success rate: 70% â†’ 95% (+25%)
- Processing time: +10-20s per 50 files
- **Net benefit: Faster completion (less retries)**

---

**Last Updated:** 12/01/2025
**Status:** Analysis Complete - Ready for Implementation
