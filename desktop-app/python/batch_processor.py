#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Batch Document Processor - Multi-Image Analysis
Supports 2 modes:
- Mode 1: Fixed batch size (5 images per batch)
- Mode 2: Smart batching (group by document boundaries)
"""

import sys
import os
import json
import base64
import re
import requests
from PIL import Image
import io

# Import existing engines
from ocr_engine_gemini_flash import resize_image_smart, parse_gemini_response


def encode_image_base64(image_path, max_width=1500, max_height=2100):
    """Encode image to base64 with smart resize"""
    try:
        img = Image.open(image_path)
        
        # Convert to RGB if needed
        if img.mode in ('RGBA', 'LA', 'P'):
            img = img.convert('RGB')
        
        # Resize
        resized_img, resize_info = resize_image_smart(img, max_width, max_height)
        
        # Encode to base64
        buffer = io.BytesIO()
        resized_img.save(buffer, format='JPEG', quality=95)
        img_bytes = buffer.getvalue()
        encoded = base64.b64encode(img_bytes).decode('utf-8')
        
        return encoded, resize_info
    except Exception as e:
        print(f"Error encoding image {image_path}: {e}", file=sys.stderr)
        return None, None


def get_multi_image_prompt():
    """Get prompt for multi-image batch analysis with full 98 document types"""
    return """Báº¡n Ä‘ang phÃ¢n tÃ­ch nhiá»u trang scan tÃ i liá»‡u Ä‘áº¥t Ä‘ai Viá»‡t Nam (cÃ³ thá»ƒ thuá»™c 1 hoáº·c nhiá»u tÃ i liá»‡u khÃ¡c nhau).

NHIá»†M Vá»¤:
1. XÃ¡c Ä‘á»‹nh cÃ³ BAO NHIÃŠU tÃ i liá»‡u khÃ¡c nhau trong cÃ¡c trang nÃ y
2. NhÃ³m cÃ¡c trang theo tÃ i liá»‡u
3. PhÃ¢n loáº¡i loáº¡i tÃ i liá»‡u cá»§a tá»«ng nhÃ³m theo DANH SÃCH 98 LOáº I bÃªn dÆ°á»›i
4. TrÃ­ch xuáº¥t metadata (ngÃ y cáº¥p cho GCN, mÃ u sáº¯c, v.v.)

Dáº¤U HIá»†U NHáº¬N BIáº¾T TRANG Má»šI vs TRANG TIáº¾P Ná»I:

TRANG 1 Cá»¦A TÃ€I LIá»†U (New Document):
- CÃ³ TIÃŠU Äá»€ CHÃNH á»Ÿ TOP 30% (Ä‘áº§u trang)
- Cá»¡ chá»¯ Lá»šN, IN HOA, cÄƒn giá»¯a
- VÃ­ dá»¥: "Há»¢P Äá»’NG CHUYá»‚N NHÆ¯á»¢NG", "ÄÆ N ÄÄ‚NG KÃ BIáº¾N Äá»˜NG"
- CÃ³ quá»‘c huy (Ä‘á»‘i vá»›i GCN)
- KhÃ¡c biá»‡t rÃµ vá» format/mÃ u sáº¯c so vá»›i trang trÆ°á»›c

TRANG TIáº¾P Ná»I (Continuation - Trang 2, 3, 4...):
- KHÃ”NG cÃ³ tiÃªu Ä‘á» chÃ­nh á»Ÿ Ä‘áº§u
- Chá»‰ cÃ³ section headers: "II.", "III.", "ÄIá»€U 2", "PHáº¦N II", "Má»¤C III"
- CÃ¹ng format/mÃ u sáº¯c vá»›i trang trÆ°á»›c
- Ná»™i dung liÃªn tá»¥c (Ä‘iá»u khoáº£n, sÆ¡ Ä‘á»“, báº£ng biá»ƒu, chá»¯ kÃ½)

RANH GIá»šI GIá»®A CÃC TÃ€I LIá»†U:
- Thay Ä‘á»•i rÃµ rá»‡t: mÃ u giáº¥y (há»“ng â†’ tráº¯ng), format (cÃ³ quá»‘c huy â†’ khÃ´ng cÃ³)
- Xuáº¥t hiá»‡n tiÃªu Ä‘á» chÃ­nh má»›i á»Ÿ TOP
- Thay Ä‘á»•i hoÃ n toÃ n vá» layout

âš ï¸ DANH SÃCH 98 LOáº I TÃ€I LIá»†U (CHá»ˆ DÃ™NG MÃƒ TRONG DANH SÃCH NÃ€Y):

ğŸ“‹ NHÃ“M 1: Báº¢N Váº¼ / Báº¢N Äá»’ (5 loáº¡i)
BMT = Báº£n mÃ´ táº£ ranh giá»›i
HSKT = Báº£n váº½ (trÃ­ch lá»¥c, Ä‘o tÃ¡ch)
BVHC = Báº£n váº½ hoÃ n cÃ´ng
BVN = Báº£n váº½ nhÃ 
SDTT = SÆ¡ Ä‘á»“ dá»± kiáº¿n tÃ¡ch thá»­a

ğŸ“‹ NHÃ“M 2: Báº¢NG KÃŠ / DANH SÃCH (4 loáº¡i)
BKKDT = Báº£ng kÃª khai diá»‡n tÃ­ch
DSCG = Báº£ng liá»‡t kÃª danh sÃ¡ch thá»­a Ä‘áº¥t
DS15 = Danh sÃ¡ch chá»§ sá»­ dá»¥ng (Máº«u 15)
DSCK = Danh sÃ¡ch cÃ´ng khai há»“ sÆ¡ cáº¥p giáº¥y

ğŸ“‹ NHÃ“M 3: BIÃŠN Báº¢N (10 loáº¡i)
BBBDG = BiÃªn báº£n bÃ¡n Ä‘áº¥u giÃ¡
BBGD = BiÃªn báº£n bÃ n giao Ä‘áº¥t
BBHDDK = BiÃªn báº£n há»™i Ä‘á»“ng Ä‘Äƒng kÃ½ Ä‘áº¥t Ä‘ai
BBNT = BiÃªn báº£n nghiá»‡m thu cÃ´ng trÃ¬nh
BBKTSS = BiÃªn báº£n kiá»ƒm tra sai sÃ³t
BBKTHT = BiÃªn báº£n kiá»ƒm tra hiá»‡n tráº¡ng
BBKTDC = BiÃªn báº£n káº¿t thÃºc cÃ´ng khai di chÃºc
KTCKCG = BiÃªn báº£n káº¿t thÃºc thÃ´ng bÃ¡o cáº¥p GCN
KTCKMG = BiÃªn báº£n káº¿t thÃºc thÃ´ng bÃ¡o máº¥t GCN
BLTT = BiÃªn lai thu thuáº¿

ğŸ“‹ NHÃ“M 4: GIáº¤Y Tá»œ CÃ NHÃ‚N (4 loáº¡i)
CCCD = CÄƒn cÆ°á»›c cÃ´ng dÃ¢n
GKS = Giáº¥y khai sinh
GKH = Giáº¥y káº¿t hÃ´n
DICHUC = Di chÃºc

ğŸ“‹ NHÃ“M 5: GIáº¤Y CHá»¨NG NHáº¬N (9 loáº¡i)
ğŸš¨ GCN = Giáº¥y chá»©ng nháº­n quyá»n sá»­ dá»¥ng Ä‘áº¥t (âŒ KHÃ”NG bao giá» tráº£ vá» GCNM/GCNC)
  âš ï¸ Báº®T BUá»˜C tÃ¬m NGÃ€Y Cáº¤P (cÃ³ thá»ƒ viáº¿t tay, format: DD/MM/YYYY hoáº·c MM/YYYY hoáº·c YYYY)
  âš ï¸ Náº¿u tháº¥y "NgÃ y XX thÃ¡ng YY nÄƒm ZZZZ" â†’ chuyá»ƒn thÃ nh "XX/YY/ZZZZ"
GXNNVTC = Giáº¥y xÃ¡c nháº­n ná»™p vÃ o ngÃ¢n sÃ¡ch
GNT = Giáº¥y ná»™p tiá»n
GSND = Giáº¥y sang nhÆ°á»£ng Ä‘áº¥t
GTLQ = Giáº¥y tá» liÃªn quan (giáº¥y tiáº¿p nháº­n, biÃªn nháº­n há»“ sÆ¡, phiáº¿u kiá»ƒm soÃ¡t)
GUQ = Giáº¥y á»§y quyá»n
GXNDKLD = Giáº¥y xÃ¡c nháº­n Ä‘Äƒng kÃ½ láº§n Ä‘áº§u
GPXD = Giáº¥y phÃ©p xÃ¢y dá»±ng

ğŸ“‹ NHÃ“M 6: Há»¢P Äá»’NG (7 loáº¡i)
HDCQ = Há»£p Ä‘á»“ng chuyá»ƒn nhÆ°á»£ng, táº·ng cho
HDUQ = Há»£p Ä‘á»“ng á»§y quyá»n
HDTHC = Há»£p Ä‘á»“ng tháº¿ cháº¥p
HDTD = Há»£p Ä‘á»“ng thuÃª Ä‘áº¥t
HDTCO = Há»£p Ä‘á»“ng thi cÃ´ng
HDBDG = Há»£p Ä‘á»“ng mua bÃ¡n Ä‘áº¥u giÃ¡
hoadon = HÃ³a Ä‘Æ¡n giÃ¡ trá»‹ gia tÄƒng

ğŸ“‹ NHÃ“M 7: ÄÆ N (15 loáº¡i)
DDKBD = ÄÆ¡n Ä‘Äƒng kÃ½ biáº¿n Ä‘á»™ng (cÃ³ "BIáº¾N Äá»˜NG")
DDK = ÄÆ¡n Ä‘Äƒng kÃ½ (khÃ´ng cÃ³ "BIáº¾N Äá»˜NG")
DCK = ÄÆ¡n cam káº¿t, giáº¥y cam káº¿t
CHTGD = ÄÆ¡n chuyá»ƒn hÃ¬nh thá»©c giao Ä‘áº¥t
DCQDGD = ÄÆ¡n Ä‘iá»u chá»‰nh quyáº¿t Ä‘á»‹nh giao Ä‘áº¥t
DMG = ÄÆ¡n miá»…n giáº£m lá»‡ phÃ­
DMD = ÄÆ¡n Ä‘a má»¥c Ä‘Ã­ch
DXN = ÄÆ¡n xÃ¡c nháº­n
DXCMD = ÄÆ¡n xin chuyá»ƒn má»¥c Ä‘Ã­ch
DGH = ÄÆ¡n xin gia háº¡n
DXGD = ÄÆ¡n xin giao Ä‘áº¥t
DXTHT = ÄÆ¡n xin tÃ¡ch/há»£p thá»­a
DXCD = ÄÆ¡n xin cáº¥p Ä‘á»•i GCN
DDCTH = ÄÆ¡n Ä‘iá»u chá»‰nh thá»i háº¡n dá»± Ã¡n
DXNTH = ÄÆ¡n xÃ¡c nháº­n thá»i háº¡n nÃ´ng nghiá»‡p

ğŸ“‹ NHÃ“M 8: QUYáº¾T Äá»ŠNH (15 loáº¡i)
QDGTD = Quyáº¿t Ä‘á»‹nh giao Ä‘áº¥t/cho thuÃª
QDCMD = Quyáº¿t Ä‘á»‹nh chuyá»ƒn má»¥c Ä‘Ã­ch
QDTH = Quyáº¿t Ä‘á»‹nh thu há»“i Ä‘áº¥t
QDGH = Quyáº¿t Ä‘á»‹nh gia háº¡n
QDTT = Quyáº¿t Ä‘á»‹nh tÃ¡ch/há»£p thá»­a
QDCHTGD = Quyáº¿t Ä‘á»‹nh chuyá»ƒn hÃ¬nh thá»©c giao Ä‘áº¥t
QDDCGD = Quyáº¿t Ä‘á»‹nh Ä‘iá»u chá»‰nh QÄ giao Ä‘áº¥t
QDDCTH = Quyáº¿t Ä‘á»‹nh Ä‘iá»u chá»‰nh thá»i háº¡n dá»± Ã¡n
QDHG = Quyáº¿t Ä‘á»‹nh há»§y GCN
QDPDBT = Quyáº¿t Ä‘á»‹nh phÃª duyá»‡t bá»“i thÆ°á»ng
QDDCQH = Quyáº¿t Ä‘á»‹nh Ä‘iá»u chá»‰nh quy hoáº¡ch
QDPDDG = Quyáº¿t Ä‘á»‹nh phÃª quyáº¿t Ä‘Æ¡n giÃ¡
QDTHA = Quyáº¿t Ä‘á»‹nh thi hÃ nh Ã¡n
QDHTSD = Quyáº¿t Ä‘á»‹nh hÃ¬nh thá»©c sá»­ dá»¥ng Ä‘áº¥t
QDXP = Quyáº¿t Ä‘á»‹nh xá»­ pháº¡t

ğŸ“‹ NHÃ“M 9: PHIáº¾U (8 loáº¡i)
PCT = Phiáº¿u chuyá»ƒn thÃ´ng tin nghÄ©a vá»¥ tÃ i chÃ­nh
PKTHS = Phiáº¿u kiá»ƒm tra há»“ sÆ¡ (KIá»‚M TRA, khÃ´ng pháº£i KIá»‚M SOÃT)
PLYKDC = Phiáº¿u láº¥y Ã½ kiáº¿n khu dÃ¢n cÆ°
PXNKQDD = Phiáº¿u xÃ¡c nháº­n káº¿t quáº£ Ä‘o Ä‘áº¡c
DKTC = Phiáº¿u yÃªu cáº§u Ä‘Äƒng kÃ½ biá»‡n phÃ¡p báº£o Ä‘áº£m
DKTD = Phiáº¿u yÃªu cáº§u thay Ä‘á»•i biá»‡n phÃ¡p báº£o Ä‘áº£m
DKXTC = Phiáº¿u yÃªu cáº§u xÃ³a Ä‘Äƒng kÃ½ biá»‡n phÃ¡p báº£o Ä‘áº£m
QR = QuÃ©t mÃ£ QR

ğŸ“‹ NHÃ“M 10: THÃ”NG BÃO (8 loáº¡i)
TBT = ThÃ´ng bÃ¡o thuáº¿
TBMG = ThÃ´ng bÃ¡o vá» viá»‡c máº¥t GCN
TBCKCG = ThÃ´ng bÃ¡o cÃ´ng khai káº¿t quáº£ cáº¥p GCN
TBCKMG = ThÃ´ng bÃ¡o niÃªm yáº¿t máº¥t GCN
HTNVTC = ThÃ´ng bÃ¡o hoÃ n thÃ nh nghÄ©a vá»¥ tÃ i chÃ­nh
TBCNBD = ThÃ´ng bÃ¡o cáº­p nháº­t biáº¿n Ä‘á»™ng
CKDC = ThÃ´ng bÃ¡o cÃ´ng bá»‘ di chÃºc
HTBTH = HoÃ n thÃ nh bá»“i thÆ°á»ng há»— trá»£

ğŸ“‹ NHÃ“M 11: Tá»œ KHAI / Tá»œ TRÃŒNH (3 loáº¡i)
TKT = Tá» khai thuáº¿
TTr = Tá» trÃ¬nh vá» giao Ä‘áº¥t (chá»¯ "r" thÆ°á»ng)
TTCG = Tá» trÃ¬nh vá» Ä‘Äƒng kÃ½ Ä‘áº¥t Ä‘ai (UBND xÃ£)

ğŸ“‹ NHÃ“M 12: VÄ‚N Báº¢N (10 loáº¡i)
CKTSR = VÄƒn báº£n cam káº¿t tÃ i sáº£n riÃªng
VBCTCMD = VÄƒn báº£n cháº¥p thuáº­n chuyá»ƒn má»¥c Ä‘Ã­ch
VBDNCT = VÄƒn báº£n Ä‘á» nghá»‹ cháº¥p thuáº­n nháº­n chuyá»ƒn nhÆ°á»£ng
PDPASDD = VÄƒn báº£n Ä‘á» nghá»‹ tháº©m Ä‘á»‹nh phÆ°Æ¡ng Ã¡n
VBTK = VÄƒn báº£n thá»a thuáº­n phÃ¢n chia DI Sáº¢N THá»ªA Káº¾
TTHGD = VÄƒn báº£n thá»a thuáº­n Há»˜ GIA ÄÃŒNH (khÃ´ng pháº£i vá»£ chá»“ng)
CDLK = VÄƒn báº£n cháº¥m dá»©t quyá»n háº¡n cháº¿ liá»n ká»
HCLK = VÄƒn báº£n xÃ¡c láº­p quyá»n háº¡n cháº¿ liá»n ká»
VBTC = VÄƒn báº£n tá»« chá»‘i nháº­n di sáº£n
PCTSVC = VÄƒn báº£n phÃ¢n chia tÃ i sáº£n Vá»¢ CHá»’NG (khÃ´ng pháº£i há»™ gia Ä‘Ã¬nh)

âš ï¸ QUAN TRá»ŒNG - QUY Táº®C PHÃ‚N LOáº I:
- CHá»ˆ phÃ¢n loáº¡i dá»±a vÃ o TIÃŠU Äá»€ CHÃNH á»Ÿ TOP 30%
- Bá» QUA section headers (ÄIá»€U 2, PHáº¦N II, ...)
- Bá» QUA mentions trong body text
- âŒ TUYá»†T Äá»I khÃ´ng tráº£ vá» GCNM hoáº·c GCNC, chá»‰ tráº£ vá» GCN
- Náº¿u khÃ´ng khá»›p 98 loáº¡i â†’ tráº£ vá» "UNKNOWN"

ğŸ¯ QUY Táº®C PHÃ‚N BIá»†T Dá»„ NHáº¦M:

**1. HDCQ vs HDUQ (Cá»°C Ká»² QUAN TRá»ŒNG):**
- HDCQ = "Há»¢P Äá»’NG CHUYá»‚N NHÆ¯á»¢NG" (transfer ownership)
  * Keywords: "CHUYá»‚N NHÆ¯á»¢NG", "Táº¶NG CHO"
  * âœ… "Há»¢P Äá»’NG CHUYá»‚N NHÆ¯á»¢NG QUYá»€N Sá»¬ Dá»¤NG Äáº¤T" â†’ HDCQ
- HDUQ = "Há»¢P Äá»’NG á»¦Y QUYá»€N" (power of attorney)
  * Keywords: "á»¦Y QUYá»€N"
  * âœ… "Há»¢P Äá»’NG á»¦Y QUYá»€N" â†’ HDUQ
- âš ï¸ KHÃ”NG nháº§m: Náº¿u tháº¥y "á»¦Y QUYá»€N" â†’ Báº®T BUá»˜C lÃ  HDUQ, khÃ´ng pháº£i HDCQ

**2. TTHGD vs PCTSVC vs VBTK (Dá»„ NHáº¦M):**
- TTHGD = Thá»a thuáº­n Há»˜ GIA ÄÃŒNH
  * Keywords: "Há»˜ GIA ÄÃŒNH" (family members)
  * âœ… "THá»A THUáº¬N QSDÄ Há»˜ GIA ÄÃŒNH" â†’ TTHGD
  * âœ… "PHÃ‚N CHIA TÃ€I Sáº¢N Há»˜ GIA ÄÃŒNH" â†’ TTHGD
- PCTSVC = PhÃ¢n chia Vá»¢ CHá»’NG
  * Keywords: "Vá»¢ CHá»’NG" (couple)
  * âœ… "PHÃ‚N CHIA TÃ€I Sáº¢N Vá»¢ CHá»’NG" â†’ PCTSVC
- VBTK = PhÃ¢n chia DI Sáº¢N THá»ªA Káº¾
  * Keywords: "DI Sáº¢N THá»ªA Káº¾", "Káº¾ THá»ªA" (inheritance)
  * âœ… "THá»A THUáº¬N PHÃ‚N CHIA DI Sáº¢N THá»ªA Káº¾" â†’ VBTK

**3. DDKBD vs DDK:**
- DDKBD = CÃ³ chá»¯ "BIáº¾N Äá»˜NG"
  * âœ… "ÄÆ N ÄÄ‚NG KÃ BIáº¾N Äá»˜NG Äáº¤T ÄAI" â†’ DDKBD
- DDK = KHÃ”NG cÃ³ "BIáº¾N Äá»˜NG"
  * âœ… "ÄÆ N ÄÄ‚NG KÃ Äáº¤T ÄAI" â†’ DDK

**4. PKTHS vs GTLQ:**
- PKTHS = "KIá»‚M TRA Há»’ SÆ "
  * âœ… "PHIáº¾U KIá»‚M TRA Há»’ SÆ " â†’ PKTHS
- GTLQ = "KIá»‚M SOÃT" hoáº·c "TIáº¾P NHáº¬N"
  * âœ… "PHIáº¾U KIá»‚M SOÃT QUÃ TRÃŒNH" â†’ GTLQ
  * âœ… "GIáº¤Y TIáº¾P NHáº¬N Há»’ SÆ " â†’ GTLQ

**5. GUQ (GIáº¤Y) vs HDUQ (Há»¢P Äá»’NG):**
- GUQ = "GIáº¤Y á»¦Y QUYá»€N" (simple authorization letter)
  * âœ… "GIáº¤Y á»¦Y QUYá»€N" â†’ GUQ
- HDUQ = "Há»¢P Äá»’NG á»¦Y QUYá»€N" (formal contract)
  * âœ… "Há»¢P Äá»’NG á»¦Y QUYá»€N" â†’ HDUQ

âŒ VÃ Dá»¤ SAI (KHÃ”NG LÃ€M NHÆ¯ Váº¦Y):
- "Há»¢P Äá»’NG á»¦Y QUYá»€N" â†’ HDCQ âŒ (Sai! Pháº£i lÃ  HDUQ)
- "PHÃ‚N CHIA TÃ€I Sáº¢N Vá»¢ CHá»’NG" â†’ TTHGD âŒ (Sai! Pháº£i lÃ  PCTSVC)
- "Giáº¥y chá»©ng nháº­n mÃ u há»“ng" â†’ GCNM âŒ (Sai! Pháº£i lÃ  GCN)
- "ÄIá»€U 2: Ná»˜I DUNG THá»A THUáº¬N" â†’ TTHGD âŒ (Section header, khÃ´ng pháº£i title)

âœ… VÃ Dá»¤ ÄÃšNG:
- Trang cÃ³ "Há»¢P Äá»’NG CHUYá»‚N NHÆ¯á»¢NG" á»Ÿ TOP â†’ HDCQ âœ…
- Trang cÃ³ "Há»¢P Äá»’NG á»¦Y QUYá»€N" á»Ÿ TOP â†’ HDUQ âœ…
- Trang cÃ³ "ÄIá»€U 2" á»Ÿ TOP â†’ UNKNOWN (continuation page) âœ…
- Trang cÃ³ "THá»A THUáº¬N...Há»˜ GIA ÄÃŒNH" â†’ TTHGD âœ…

ğŸš¨ Äáº¶C BIá»†T Vá»šI GCN:
- LuÃ´n tráº£ vá» "GCN" (khÃ´ng pháº£i GCNM/GCNC)
- Báº®T BUá»˜C tÃ¬m NGÃ€Y Cáº¤P (issue_date) á»Ÿ má»i trang
- Format ngÃ y: DD/MM/YYYY (hoáº·c MM/YYYY, YYYY náº¿u má»)
- Vá»‹ trÃ­: ThÆ°á»ng á»Ÿ trang 2, bottom, gáº§n chá»¯ kÃ½/con dáº¥u
- Náº¿u khÃ´ng tÃ¬m tháº¥y â†’ issue_date: null, issue_date_confidence: "not_found"

OUTPUT JSON:
{
  "documents": [
    {
      "type": "HDCQ",
      "pages": [0, 1, 2],
      "confidence": 0.95,
      "reasoning": "3 trang Ä‘áº§u cÃ¹ng format, trang 0 cÃ³ tiÃªu Ä‘á» 'Há»¢P Äá»’NG CHUYá»‚N NHÆ¯á»¢NG QUYá»€N Sá»¬ Dá»¤NG Äáº¤T'",
      "metadata": {}
    },
    {
      "type": "GCN",
      "pages": [3, 4],
      "confidence": 0.98,
      "reasoning": "Trang 3-4 lÃ  GCN mÃ u há»“ng, cÃ³ quá»‘c huy, tÃ¬m tháº¥y ngÃ y cáº¥p á»Ÿ trang 4",
      "metadata": {
        "color": "pink",
        "issue_date": "27/10/2021",
        "issue_date_confidence": "full"
      }
    }
  ]
}

ğŸš¨ Cá»°C Ká»² QUAN TRá»ŒNG - Báº®T BUá»˜C RETURN Táº¤T Cáº¢ PAGES:
- Báº¡n PHáº¢I assign Má»ŒI page vÃ o 1 document
- Náº¿u page khÃ´ng rÃµ rÃ ng â†’ assign vÃ o document "UNKNOWN"
- KHÃ”NG BAO GIá»œ bá» qua báº¥t ká»³ page nÃ o
- VÃ­ dá»¥: Náº¿u cÃ³ 20 pages â†’ "pages" arrays pháº£i cover háº¿t 0-19

VÃ Dá»¤ ÄÃšNG (20 pages):
{
  "documents": [
    {"type": "HDCQ", "pages": [0,1,2,3,4], ...},      // 5 pages
    {"type": "GCN", "pages": [5,6,7,8], ...},         // 4 pages
    {"type": "DDKBD", "pages": [9,10,11], ...},       // 3 pages
    {"type": "UNKNOWN", "pages": [12,13,14,15,16,17,18,19], ...}  // 8 unclear pages
  ]
}
â†’ Total pages: 5+4+3+8 = 20 âœ… (ALL pages covered)

VÃ Dá»¤ SAI:
{
  "documents": [
    {"type": "HDCQ", "pages": [0,1,2,3,4], ...},
    {"type": "GCN", "pages": [5,6,7,8], ...}
  ]
}
â†’ Total pages: 5+4 = 9 âŒ (Missing pages 9-19!)

LÆ°u Ã½:
- pages dÃ¹ng 0-indexed (trang Ä‘áº§u tiÃªn = 0)
- Náº¿u khÃ´ng cháº¯c cháº¯n, Ä‘Ã¡nh dáº¥u confidence tháº¥p
- Náº¿u chá»‰ cÃ³ 1 tÃ i liá»‡u, váº«n tráº£ vá» array vá»›i 1 pháº§n tá»­
"""


def batch_classify_fixed(image_paths, api_key, batch_size=5, overlap=3):
    """
    PhÆ°Æ¡ng Ã¡n 1: Fixed Batch Size vá»›i OVERLAP
    Gom má»—i 5 files nhÆ°ng overlap 3 files Ä‘á»ƒ giá»¯ context
    
    VÃ­ dá»¥ overlap=3, batch_size=15:
      Batch 1: Files 0-14  (15 files)
      Batch 2: Files 12-29 (18 files) â†’ Overlap files 12,13,14
      Batch 3: Files 27-44 (18 files) â†’ Overlap files 27,28,29
      
    Táº¡i sao? File 15,16,17 cÃ³ thá»ƒ lÃ  continuation cá»§a file 14.
    Náº¿u batch 2 khÃ´ng tháº¥y file 14 â†’ classify sai!
    """
    print(f"\n{'='*80}", file=sys.stderr)
    print(f"ğŸ”„ BATCH MODE 1: Fixed Batch Size ({batch_size} files, overlap {overlap})", file=sys.stderr)
    print(f"{'='*80}", file=sys.stderr)
    
    all_results = []
    processed_files = set()  # Track processed files to detect missing ones
    batch_num = 0
    current_idx = 0
    
    while current_idx < len(image_paths):
        batch_num += 1
        
        # Calculate batch range with overlap
        batch_start = max(0, current_idx - overlap) if batch_num > 1 else current_idx
        batch_end = min(len(image_paths), current_idx + batch_size)
        batch_paths = image_paths[batch_start:batch_end]
        
        # Track which files are NEW in this batch (not overlap)
        new_file_start_idx = current_idx - batch_start
        
        print(f"\nğŸ“¦ Batch {batch_num}: Files {batch_start}-{batch_end-1} ({len(batch_paths)} images)", file=sys.stderr)
        if batch_num > 1:
            print(f"   â†©ï¸ Overlap: {overlap} files from previous batch (for context)", file=sys.stderr)
            print(f"   ğŸ†• New files: {batch_end - current_idx} (starting from index {new_file_start_idx})", file=sys.stderr)
        
        for i, path in enumerate(batch_paths):
            marker = "ğŸ†•" if i >= new_file_start_idx else "â†©ï¸"
            print(f"   [{i}] {marker} {os.path.basename(path)}", file=sys.stderr)
        
        # Encode all images in batch
        print(f"ğŸ–¼ï¸ Encoding {len(batch_paths)} images...", file=sys.stderr)
        encoded_images = []
        for path in batch_paths:
            encoded, resize_info = encode_image_base64(path)
            if encoded:
                encoded_images.append(encoded)
                print(f"   âœ… {os.path.basename(path)}: {resize_info.get('original_size', 'N/A')} â†’ {resize_info.get('new_size', 'N/A')}", file=sys.stderr)
            else:
                print(f"   âŒ Failed to encode {os.path.basename(path)}", file=sys.stderr)
        
        if not encoded_images:
            print(f"âŒ No valid images in batch {batch_num}", file=sys.stderr)
            continue
        
        # Build multi-image payload
        parts = [{"text": get_multi_image_prompt()}]
        for img_data in encoded_images:
            parts.append({
                "inline_data": {
                    "mime_type": "image/jpeg",
                    "data": img_data
                }
            })
        
        payload = {
            "contents": [{"parts": parts}],
            "generationConfig": {
                "temperature": 0.1,
                "topP": 0.8,
                "topK": 10,
                "maxOutputTokens": 8000,  # Large enough for 20 documents Ã— 400 tokens each
                "responseMimeType": "application/json"  # Force JSON output
            },
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"}
            ]
        }
        
        # Call Gemini API
        print(f"ğŸ“¡ Sending batch request to Gemini Flash...", file=sys.stderr)
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={api_key}"
        
        try:
            response = requests.post(api_url, json=payload, timeout=120)
            response.raise_for_status()
            result_data = response.json()
            
            print(f"ğŸ“Š Response status: {response.status_code}", file=sys.stderr)
            
            # Parse response
            if 'candidates' in result_data and len(result_data['candidates']) > 0:
                candidate = result_data['candidates'][0]
                if 'content' in candidate and 'parts' in candidate['content']:
                    parts = candidate['content']['parts']
                    if len(parts) > 0 and 'text' in parts[0]:
                        response_text = parts[0]['text']
                        
                        print(f"ğŸ“„ Raw response preview: {response_text[:200]}...", file=sys.stderr)
                        
                        # Extract JSON from response - try multiple patterns
                        json_match = re.search(r'\{[\s\S]*"documents"[\s\S]*\}', response_text)
                        if not json_match:
                            # Try finding JSON with triple backticks
                            json_match = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', response_text)
                            if json_match:
                                response_text = json_match.group(1)
                            else:
                                # Try finding any JSON object
                                json_match = re.search(r'(\{[\s\S]*\})', response_text)
                                if json_match:
                                    response_text = json_match.group(1)
                        else:
                            response_text = json_match.group(0)
                        
                        if response_text:
                            try:
                                batch_result = json.loads(response_text)
                            
                                print(f"âœ… Batch {batch_num} complete:", file=sys.stderr)
                                
                                # Validate: Check if all pages are covered
                                total_pages_in_batch = len(batch_paths)
                                pages_returned = set()
                                
                                for doc in batch_result.get('documents', []):
                                    doc_type = doc.get('type', 'UNKNOWN')
                                    pages = doc.get('pages', [])
                                    confidence = doc.get('confidence', 0)
                                    print(f"   ğŸ“„ {doc_type}: {len(pages)} pages, confidence {confidence:.0%}", file=sys.stderr)
                                    
                                    # Collect all page indices
                                    for p in pages:
                                        pages_returned.add(p)
                                
                                # Check for missing pages
                                expected_pages = set(range(total_pages_in_batch))
                                missing_pages = expected_pages - pages_returned
                                
                                if missing_pages:
                                    print(f"   âš ï¸ WARNING: AI didn't return {len(missing_pages)} pages: {sorted(missing_pages)}", file=sys.stderr)
                                    print(f"      These files will be processed by fallback", file=sys.stderr)
                                else:
                                    print(f"   âœ… All {total_pages_in_batch} pages accounted for", file=sys.stderr)
                                
                                # Map results back to original file paths
                                # ONLY process NEW files (skip overlap files)
                                for doc in batch_result.get('documents', []):
                                    for page_idx in doc.get('pages', []):
                                        # Check if this is a NEW file (not overlap)
                                        if page_idx >= new_file_start_idx and page_idx < len(batch_paths):
                                            file_path = batch_paths[page_idx]
                                            
                                            # Skip if already processed (from previous batch)
                                            if file_path in processed_files:
                                                print(f"   â­ï¸ Skipping duplicate: {os.path.basename(file_path)}", file=sys.stderr)
                                                continue
                                            
                                            processed_files.add(file_path)  # Track this file
                                            all_results.append({
                                                'file_path': file_path,
                                                'file_name': os.path.basename(file_path),
                                                'short_code': doc.get('type', 'UNKNOWN'),
                                                'confidence': doc.get('confidence', 0.5),
                                                'reasoning': doc.get('reasoning', ''),
                                                'metadata': doc.get('metadata', {}),
                                                'method': 'batch_fixed',
                                                'batch_num': batch_num
                                            })
                            except json.JSONDecodeError as je:
                                print(f"âš ï¸ JSON decode error in batch {batch_num}: {je}", file=sys.stderr)
                                print(f"   Response text: {response_text[:500]}...", file=sys.stderr)
                        else:
                            print(f"âš ï¸ No valid JSON in response for batch {batch_num}", file=sys.stderr)
            
        except Exception as e:
            print(f"âŒ Batch {batch_num} error: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc(file=sys.stderr)
        
        # Move to next batch (increment by batch_size, not batch_end)
        current_idx += batch_size
    
    print(f"\n{'='*80}", file=sys.stderr)
    print(f"âœ… BATCH MODE 1 COMPLETE: {len(all_results)} files processed", file=sys.stderr)
    
    # Detect missing files
    all_input_files = set(image_paths)
    missing_files = all_input_files - processed_files
    
    if missing_files:
        print(f"âš ï¸ WARNING: {len(missing_files)} files were NOT processed by AI:", file=sys.stderr)
        for missing_file in sorted(missing_files):
            print(f"   âŒ {os.path.basename(missing_file)}", file=sys.stderr)
        print(f"   Possible causes: AI didn't return page indices, JSON parsing error", file=sys.stderr)
        print(f"\nğŸ”„ FALLBACK: Processing {len(missing_files)} missing files individually...", file=sys.stderr)
        
        # Fallback: Process missing files with single-file tier1 scan
        for missing_file in sorted(missing_files):
            try:
                print(f"   ğŸ”„ Processing {os.path.basename(missing_file)}...", file=sys.stderr)
                result = quick_scan_tier1(missing_file, api_key)
                all_results.append({
                    'file_path': missing_file,
                    'file_name': os.path.basename(missing_file),
                    'short_code': result.get('short_code', 'UNKNOWN'),
                    'confidence': result.get('confidence', 0.5),
                    'reasoning': result.get('reasoning', 'Fallback single-file scan'),
                    'metadata': result.get('metadata', {}),
                    'method': 'batch_fallback',
                    'batch_num': 'fallback'
                })
                print(f"      âœ… {result.get('short_code', 'UNKNOWN')} ({result.get('confidence', 0):.0%})", file=sys.stderr)
            except Exception as e:
                print(f"      âŒ Error: {e}", file=sys.stderr)
                # Add as UNKNOWN if fallback also fails
                all_results.append({
                    'file_path': missing_file,
                    'file_name': os.path.basename(missing_file),
                    'short_code': 'UNKNOWN',
                    'confidence': 0.0,
                    'reasoning': f'Fallback failed: {str(e)}',
                    'metadata': {},
                    'method': 'batch_fallback_failed',
                    'batch_num': 'fallback'
                })
        
        print(f"âœ… Fallback complete: {len(all_results)} total results (original + fallback)", file=sys.stderr)
    else:
        print(f"âœ… All {len(all_input_files)} input files were successfully processed", file=sys.stderr)
    
    print(f"{'='*80}", file=sys.stderr)
    
    return all_results


def quick_scan_tier1(image_path, api_key):
    """Quick scan vá»›i Tier 1 Ä‘á»ƒ detect document boundaries"""
    from ocr_engine_gemini_flash import classify_document_gemini_flash
    
    try:
        result = classify_document_gemini_flash(
            image_path=image_path,
            api_key=api_key,
            crop_top_percent=0.60,
            model_type='gemini-flash-lite',
            enable_resize=True,
            max_width=1500,
            max_height=2100
        )
        return result
    except Exception as e:
        print(f"Quick scan error for {image_path}: {e}", file=sys.stderr)
        return {'short_code': 'ERROR', 'confidence': 0}


def group_by_document(quick_results, file_paths):
    """
    NhÃ³m files thÃ nh documents dá»±a trÃªn quick scan results
    Returns: List of document groups [[0,1,2], [3,4], [5,6,7,8], ...]
    """
    print(f"\nğŸ§  Analyzing document boundaries...", file=sys.stderr)
    
    groups = []
    current_group = [0]
    last_type = quick_results[0].get('short_code', 'UNKNOWN')
    
    for i in range(1, len(quick_results)):
        result = quick_results[i]
        short_code = result.get('short_code', 'UNKNOWN')
        confidence = result.get('confidence', 0)
        reasoning = result.get('reasoning', '').lower()
        
        # Check if this is a new document
        is_new_document = False
        
        # High confidence with clear title â†’ New document
        if confidence >= 0.8 and short_code != 'UNKNOWN':
            is_new_document = True
            print(f"   ğŸ“„ [{i}] New document detected: {short_code} ({confidence:.0%})", file=sys.stderr)
        
        # Low confidence + continuation indicators â†’ Same document
        elif confidence < 0.5 and any(kw in reasoning for kw in ['section header', 'ii.', 'iii.', 'thá»­a Ä‘áº¥t']):
            is_new_document = False
            print(f"   â¡ï¸ [{i}] Continuation page: {short_code} ({confidence:.0%})", file=sys.stderr)
        
        # Borderline case - use confidence
        else:
            is_new_document = (confidence >= 0.7)
            print(f"   â“ [{i}] Borderline: {short_code} ({confidence:.0%}) â†’ {'New' if is_new_document else 'Continue'}", file=sys.stderr)
        
        if is_new_document:
            # Start new group
            groups.append(current_group)
            current_group = [i]
            last_type = short_code
        else:
            # Continue current group
            current_group.append(i)
    
    # Add last group
    if current_group:
        groups.append(current_group)
    
    print(f"\nâœ… Grouped into {len(groups)} documents:", file=sys.stderr)
    for g_idx, group in enumerate(groups):
        print(f"   Document {g_idx + 1}: {len(group)} pages {group}", file=sys.stderr)
    
    return groups


def batch_classify_smart(image_paths, api_key):
    """
    PhÆ°Æ¡ng Ã¡n 2: Smart Batching - TRUE AI-POWERED vá»›i OVERLAP
    Gá»­i nhiá»u files (10-20) vá»›i overlap Ä‘á»ƒ AI cÃ³ full context
    """
    print(f"\n{'='*80}", file=sys.stderr)
    print(f"ğŸ§  BATCH MODE 2: Smart Batching (AI Document Detection)", file=sys.stderr)
    print(f"{'='*80}", file=sys.stderr)
    
    total_files = len(image_paths)
    
    # Smart batch size strategy vá»›i overlap
    if total_files <= 20:
        # Small batch: Send all at once, no overlap needed
        batch_size = total_files
        overlap = 0
        print(f"ğŸ“Š Strategy: Send ALL {total_files} files in 1 batch", file=sys.stderr)
    elif total_files <= 60:
        # Medium batch: 20 files per batch, 5 files overlap
        batch_size = 20
        overlap = 5
        print(f"ğŸ“Š Strategy: Send {batch_size} files per batch vá»›i {overlap} files overlap", file=sys.stderr)
    else:
        # Large batch: 15 files per batch, 4 files overlap
        batch_size = 15
        overlap = 4
        print(f"ğŸ“Š Strategy: Send {batch_size} files per batch vá»›i {overlap} files overlap (large dataset)", file=sys.stderr)
    
    if overlap > 0:
        print(f"   â†©ï¸ Overlap purpose: Batch sau tháº¥y {overlap} files cuá»‘i cá»§a batch trÆ°á»›c", file=sys.stderr)
        print(f"   Why? File 16 khÃ´ng cÃ³ title â†’ cáº§n tháº¥y file 14-15 Ä‘á»ƒ biáº¿t nÃ³ thuá»™c document nÃ o", file=sys.stderr)
    
    print(f"   AI needs 10-20 files to detect document boundaries accurately", file=sys.stderr)
    
    # Use fixed batch with smart size + overlap
    return batch_classify_fixed(image_paths, api_key, batch_size=batch_size, overlap=overlap)


# CLI interface for testing
if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Usage: python batch_processor.py <mode> <api_key> <image1> <image2> ...", file=sys.stderr)
        print("Modes: fixed, smart", file=sys.stderr)
        print("Example: python batch_processor.py fixed AIza... img1.jpg img2.jpg img3.jpg", file=sys.stderr)
        sys.exit(1)
    
    mode = sys.argv[1]
    api_key = sys.argv[2]
    image_paths = sys.argv[3:]
    
    print(f"ğŸ” Batch processing {len(image_paths)} images in '{mode}' mode", file=sys.stderr)
    
    if mode == 'fixed':
        results = batch_classify_fixed(image_paths, api_key, batch_size=5, overlap=2)
    elif mode == 'smart':
        results = batch_classify_smart(image_paths, api_key)
    else:
        print(f"âŒ Unknown mode: {mode}", file=sys.stderr)
        sys.exit(1)
    
    # Output JSON to stdout for IPC
    print(json.dumps(results, ensure_ascii=False))
    
    print(f"\nğŸ“Š BATCH COMPLETE: {len(results)} files processed", file=sys.stderr)
