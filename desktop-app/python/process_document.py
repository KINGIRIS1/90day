#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Standalone document processor for desktop app
Combines OCR + Rule-based classification for offline processing
"""
import sys
import json
import os
from pathlib import Path
import warnings

# Force UTF-8 encoding BEFORE any other imports
import io

# Reconfigure stdout/stderr for UTF-8
if sys.platform == 'win32':
    try:
        # Wrap binary buffers with UTF-8 text wrappers
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
    except Exception:
        # Fallback - already wrapped or other issue
        pass

# Suppress warnings
warnings.filterwarnings('ignore')
os.environ['GLOG_minloglevel'] = '2'
os.environ['FLAGS_use_mkldnn'] = '0'

# Add current directory to path
sys.path.insert(0, os.path.dirname(__file__))

# Import rule classifier (always needed)
from rule_classifier import RuleClassifier

# Lazy import OCR engines only when needed
# This allows Google/Azure to work even if Tesseract dependencies are missing
tesseract_engine = None
vietocr_engine = None
easyocr_engine = None


def extract_document_title_from_text(text: str) -> str:
    """
    Extract document title from OCR text using common patterns
    
    Vietnamese admin documents have titles like:
    - ƒê∆†N ƒêƒÇNG K√ù BI·∫æN ƒê·ªòNG...
    - H·ª¢P ƒê·ªíNG CHUY·ªÇN NH∆Ø·ª¢NG...
    - GI·∫§Y CH·ª®NG NH·∫¨N...
    - GI·∫§Y ·ª¶Y QUY·ªÄN...
    - GI·∫§Y TI·∫æP NH·∫¨N H·ªí S∆† V√Ä H·∫∏N TR·∫¢ K·∫æT QU·∫¢
    
    Args:
        text: Full OCR text
        
    Returns:
        Extracted title or empty string if not found
    """
    import re
    
    # Common title patterns (case insensitive, flexible with OCR errors)
    # IMPORTANT: Order matters! More specific patterns should come first
    # Vietnamese vowel variations (all tones):
    # E: [E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ] - E, √ä + 5 tones
    # O: [O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢] - O, √î, ∆† + all tones
    # U: [U∆Ø√ö√ô·ª¶≈®·ª§·ª®·ª™·ª¨·ªÆ·ª∞] - U, ∆Ø + all tones
    title_patterns = [
        # GI·∫§Y TI·∫æP NH·∫¨N H·ªí S∆† V√Ä H·∫∏N TR·∫¢ K·∫æT QU·∫¢ (GTLQ)
        # Ch·∫•p nh·∫≠n l·ªói OCR ph·ªï bi·∫øn: H·ªí‚ÜíH·ªé, K·∫æT‚ÜíK√âT, thi·∫øu d·∫•u
        r'(GI[A√Å·∫§]Y\s+TI[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]P\s+NH[·∫¨AƒÇ√Ç√Å√Ä√É·∫†√Ç·∫§ƒÇ·∫Æ]N\s+H[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢][\s]*S[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]|GI[A√Å·∫§]Y\s+TI[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]P\s+NH[·∫¨AƒÇ√Ç√Å√Ä√É·∫†√Ç·∫§ƒÇ·∫Æ]N\s+H·ªé\s*S∆†)\s+V[√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥]\s+H·∫∏N\s+TR·∫¢\s+K[√äE]T\s+QU·∫¢',
        
        # ƒê∆†N ƒêƒÇNG K√ù BI·∫æN ƒê·ªòNG
        r'(ƒê[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]N\s+[ƒêD][AƒÇ]NG\s+K[Y√ù]\s+BI[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N\s+[ƒêD][O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]NG(?:\s+[ƒêD][A√Å·∫§]T\s+[ƒêD]AI)?(?:\s*,?\s*T[A√Ä]I\s+S[A·∫¢]N)?(?:\s+G[A·∫Æ]N\s+LI[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N\s+V[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]I\s+[ƒêD][A√Å·∫§]T)?)',
        
        # H·ª¢P ƒê·ªíNG CHUY·ªÇN NH∆Ø·ª¢NG (check FIRST - more specific than HDUQ)
        # CRITICAL: Must check BEFORE "H·ª¢P ƒê·ªíNG ·ª¶Y QUY·ªÄN" to avoid false matches
        # "H·ª¢P ƒê·ªíNG CHUY·ªÇN NH∆Ø·ª¢NG QUY·ªÄN S·ª¨ D·ª§NG ƒê·∫§T" should match HDCQ, not HDUQ
        r'(H[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]P\s+[ƒêD][O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]NG\s+CHUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N\s+NH[U∆Ø√ö√ô·ª¶≈®·ª§·ª®·ª™·ª¨·ªÆ·ª∞][O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]NG(?:\s+QUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N)?(?:\s+S[U∆Ø√ö√ô·ª¶≈®·ª§·ª®·ª™·ª¨·ªÆ·ª∞]\s+D[U·ª§]NG\s+[ƒêD][A√Å·∫§]T)?)',
        
        # H·ª¢P ƒê·ªíNG ·ª¶Y QUY·ªÄN (check AFTER HDCQ)
        # Flexible with: ·ª¶Y (correct), U·ª∂ (U+·ª∂ OCR error), ·ª¶ Y (with space), UY (no accents)
        r'(H[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]P\s+[ƒêD][O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]NG\s+(?:[U·ª¶][\s·ª∂]*Y|U[·ª∂Y])\s+QUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N)',
        
        # GI·∫§Y CH·ª®NG NH·∫¨N QUY·ªÄN S·ª¨ D·ª§NG ƒê·∫§T
        r'(GI[A√Å·∫§]Y\s+CH[U∆Ø√ö√ô·ª¶≈®·ª§·ª®·ª™·ª¨·ªÆ·ª∞]NG\s+NH[A·∫¨]N\s+QUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N\s+S[U∆Ø√ö√ô·ª¶≈®·ª§·ª®·ª™·ª¨·ªÆ·ª∞]\s+D[U·ª§]NG\s+[ƒêD][A√Å·∫§]T)',
        
        # GI·∫§Y ·ª¶Y QUY·ªÄN
        # Flexible with: ·ª¶Y, U·ª∂ (OCR error), ·ª¶ Y, UY
        r'(GI[A√Å·∫§]Y\s+(?:[U·ª¶][\s·ª∂]*Y|U[·ª∂Y])\s+QUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N)',
        
        # QUY·∫æT ƒê·ªäNH
        r'(QUY[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]T\s+[ƒêD][I·ªä]NH(?:\s+[A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥ƒê√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏]{1,30})?)',
        
        # ƒê∆†N XIN
        r'(ƒê[O√î∆†√ì√í·ªé√ï·ªå·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢]N\s+XIN(?:\s+[A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥ƒê√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏]{1,30})?)',
        
        # BI√äN B·∫¢N
        r'(BI[E√ä√â√à·∫æ·ªÄ·ªÇ·ªÑ·ªÜ]N\s+B[A·∫¢]N(?:\s+[A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥ƒê√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏]{1,30})?)',
    ]
    
    for pattern in title_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            title = match.group(1).strip()
            # Debug: Log matched pattern for troubleshooting
            import sys
            print(f"üéØ Pattern matched: {pattern[:50]}... ‚Üí Extracted: '{title[:80]}'", file=sys.stderr)
            
            # Clean up: remove trailing lowercase text or noise
            # Keep only the uppercase title part
            title = re.sub(r'\s+[a-z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µƒë√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπ].*$', '', title)
            
            if title and len(title) < 200:
                return title
    
    return ""


def process_document(file_path: str, ocr_engine_type: str = 'tesseract', cloud_api_key: str = None, cloud_endpoint: str = None) -> dict:
    """
    Process a document using OCR + Rules with font height detection
    
    Args:
        file_path: Path to the image file
        ocr_engine_type: 'tesseract', 'vietocr', 'easyocr', 'google', 'azure', or 'gemini-flash'
        cloud_api_key: API key for cloud OCR/AI (Google/Azure/Gemini)
        cloud_endpoint: Endpoint URL for Azure (optional for Google/Gemini)
    
    Returns classification result with confidence
    """
    try:
        # Handle Gemini Flash (AI classification) - POSITION-AWARE APPROACH
        if ocr_engine_type == 'gemini-flash':
            if not cloud_api_key:
                return {
                    "success": False,
                    "error": "Google API key is required for Gemini Flash",
                    "method": "config_error"
                }
            
            print("ü§ñ Using Gemini Flash AI with POSITION-AWARE classification", file=sys.stderr)
            
            # Import classification function
            from ocr_engine_gemini_flash import classify_document_gemini_flash
            from rule_classifier import classify_document_name_from_code
            import time
            
            # SINGLE SCAN with full image (position-aware)
            print("üì∏ Scanning FULL IMAGE with position-aware analysis...", file=sys.stderr)
            start_time = time.time()
            
            result = classify_document_gemini_flash(file_path, cloud_api_key, crop_top_percent=1.0)
            
            scan_time = time.time() - start_time
            print(f"‚è±Ô∏è Result: {result.get('short_code')} (confidence: {result.get('confidence'):.2f}, position: {result.get('title_position', 'unknown')}, time: {scan_time:.1f}s)", file=sys.stderr)
            
            # Check for errors
            if result.get("short_code") == "ERROR":
                return {
                    "success": False,
                    "error": result.get("reasoning", "Gemini Flash error"),
                    "method": "gemini_flash_failed"
                }
            
            # Validate position-aware classification
            title_position = result.get("title_position", "unknown")
            short_code = result.get("short_code", "UNKNOWN")
            
            # If title found in middle/bottom (not top), it's likely a mention, not a title
            if title_position in ["middle", "bottom"] and short_code != "UNKNOWN":
                print(f"‚ö†Ô∏è Title found at {title_position} (not top), treating as mention", file=sys.stderr)
                # Override to UNKNOWN since title is not at top
                result["short_code"] = "UNKNOWN"
                result["confidence"] = 0.1
                result["reasoning"] = f"Text pattern found at {title_position}, not a main title"
            
            method_used = "gemini_position_aware"
                    'full_time': f"{full_time:.1f}s" if result_full.get("short_code") != "ERROR" else "N/A",
                    'total_time': f"{crop_time + full_time:.1f}s" if result_full.get("short_code") != "ERROR" else f"{crop_time:.1f}s",
                    'used_full': result_full.get("short_code") != "ERROR"
                }
            else:
                print(f"‚úÖ High confidence ({confidence_crop:.2f}), using crop result only", file=sys.stderr)
                result = result_crop
                method_used = "gemini_crop_only"
                
                # Add statistics
                result['hybrid_stats'] = {
                    'crop_result': short_code_crop,
                    'crop_confidence': confidence_crop,
                    'crop_time': f"{crop_time:.1f}s",
                    'used_full': False
                }
            
            # Map Gemini result to rule_classifier format
            short_code = result.get("short_code", "UNKNOWN")
            doc_name = classify_document_name_from_code(short_code)
            
            return {
                "success": True,
                "type": short_code,
                "doc_type": doc_name,
                "short_code": short_code,
                "confidence": result.get("confidence", 0.5),
                "matched_keywords": [result.get("reasoning", "AI classification")],
                "title_boost_applied": True if short_code != "UNKNOWN" else False,
                "title_extracted_via_pattern": True if short_code != "UNKNOWN" else False,
                "reasoning": result.get("reasoning", ""),
                "method": method_used,
                "accuracy_estimate": f"{int(result.get('confidence', 0.5) * 100)}%",
                "recommend_cloud_boost": False,
                "avg_font_height": 0,
                "hybrid_stats": result.get('hybrid_stats', {})
            }
        
        # Handle Cloud OCR engines
        if ocr_engine_type == 'google':
            if not cloud_api_key:
                return {
                    "success": False,
                    "error": "Google Cloud Vision API key is required",
                    "method": "config_error"
                }
            
            print("‚òÅÔ∏è Using Google Cloud Vision", file=sys.stderr)
            
            # Import and run Google OCR
            from ocr_engine_google import ocr_google_cloud_vision
            text, confidence, error = ocr_google_cloud_vision(file_path, cloud_api_key)
            
            if error:
                return {
                    "success": False,
                    "error": error,
                    "method": "cloud_ocr_failed"
                }
            
            engine_name = "Google Cloud Vision"
            extracted_text = text
            ocr_confidence = confidence
            
        elif ocr_engine_type == 'azure':
            if not cloud_api_key or not cloud_endpoint:
                return {
                    "success": False,
                    "error": "Azure Computer Vision API key and endpoint are required",
                    "method": "config_error"
                }
            
            print("‚òÅÔ∏è Using Azure Computer Vision", file=sys.stderr)
            
            # Import and run Azure OCR
            from ocr_engine_azure import ocr_azure_computer_vision
            text, confidence, error = ocr_azure_computer_vision(file_path, cloud_api_key, cloud_endpoint)
            
            if error:
                return {
                    "success": False,
                    "error": error,
                    "method": "cloud_ocr_failed"
                }
            
            engine_name = "Azure Computer Vision"
            extracted_text = text
            ocr_confidence = confidence
            
        else:
            # Offline OCR engines - Lazy load on demand
            global tesseract_engine, vietocr_engine, easyocr_engine
            
            # Select OCR engine based on preference
            if ocr_engine_type == 'vietocr':
                # Lazy load VietOCR
                if vietocr_engine is None:
                    try:
                        from ocr_engine_vietocr import OCREngine as VietOCREngine
                        vietocr_engine = VietOCREngine()
                        print("‚úÖ VietOCR engine loaded", file=sys.stderr)
                    except Exception as e:
                        print(f"‚ö†Ô∏è VietOCR load failed: {e}, falling back to Tesseract", file=sys.stderr)
                
                if vietocr_engine is not None:
                    ocr_engine = vietocr_engine
                    engine_name = "VietOCR"
                    print("üîç Using VietOCR engine", file=sys.stderr)
                else:
                    # Fallback to Tesseract
                    if tesseract_engine is None:
                        from ocr_engine_tesseract import OCREngine as TesseractEngine
                        tesseract_engine = TesseractEngine()
                    ocr_engine = tesseract_engine
                    engine_name = "Tesseract"
                    
            elif ocr_engine_type == 'easyocr':
                # Lazy load EasyOCR
                if easyocr_engine is None:
                    try:
                        from ocr_engine_easyocr import OCREngine as EasyOCREngine
                        easyocr_engine = EasyOCREngine()
                        print("‚úÖ EasyOCR engine loaded", file=sys.stderr)
                    except Exception as e:
                        print(f"‚ö†Ô∏è EasyOCR load failed: {e}, falling back to Tesseract", file=sys.stderr)
                
                if easyocr_engine is not None:
                    ocr_engine = easyocr_engine
                    engine_name = "EasyOCR"
                    print("üîç Using EasyOCR engine", file=sys.stderr)
                else:
                    # Fallback to Tesseract
                    if tesseract_engine is None:
                        from ocr_engine_tesseract import OCREngine as TesseractEngine
                        tesseract_engine = TesseractEngine()
                    ocr_engine = tesseract_engine
                    engine_name = "Tesseract"
                    
            else:
                # Default to Tesseract
                if tesseract_engine is None:
                    try:
                        from ocr_engine_tesseract import OCREngine as TesseractEngine
                        tesseract_engine = TesseractEngine()
                        print("‚úÖ Tesseract engine loaded", file=sys.stderr)
                    except Exception as e:
                        return {
                            "success": False,
                            "error": f"Tesseract not available: {e}",
                            "method": "engine_load_failed"
                        }
                
                ocr_engine = tesseract_engine
                engine_name = "Tesseract"
                print("üîç Using Tesseract engine", file=sys.stderr)
            
            # Extract text using selected OCR engine (returns dict with full_text, title_text, avg_height)
            ocr_result = ocr_engine.extract_text(file_path)
            
            # Handle both old format (string) and new format (dict) for backward compatibility
            if isinstance(ocr_result, dict):
                extracted_text = ocr_result.get('full_text', '')
                title_text = ocr_result.get('title_text', '')
                avg_height = ocr_result.get('avg_height', 0)
            else:
                # Old format: just a string
                extracted_text = ocr_result
                title_text = extracted_text
                avg_height = 0
            
            ocr_confidence = None  # Not available for offline engines
        
        classifier = RuleClassifier()
        
        if not extracted_text or extracted_text.strip() == "":
            return {
                "success": False,
                "error": "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t text t·ª´ ·∫£nh",
                "method": "ocr_failed"
            }
        
        # Debug: Print full extracted text to see what OCR captured
        print(f"üìù Full text (first 500 chars): {extracted_text[:500]}", file=sys.stderr)
        
        # Try to extract real title from full text using patterns
        extracted_title = extract_document_title_from_text(extracted_text)
        
        if extracted_title:
            print(f"‚úÖ Extracted title via pattern: {extracted_title[:80]}...", file=sys.stderr)
        else:
            print("‚ö†Ô∏è No title pattern found in full text", file=sys.stderr)
        
        # Priority:
        # 1. If we found a title via patterns ‚Üí use it
        # 2. Otherwise use title_text from OCR (or full text for cloud)
        if extracted_title:
            final_title = extracted_title
        elif ocr_engine_type in ['google', 'azure']:
            # For cloud OCR, use extracted text (no separate title_text)
            final_title = extracted_text
        else:
            final_title = title_text
        
        # Classify using rules with title text priority
        # Pass engine type to classifier for smart title validation
        result = classifier.classify(extracted_text, title_text=final_title, ocr_engine=ocr_engine_type)
        
        # Handle case where classification completely fails (no doc_type found)
        if not result or 'doc_type' not in result:
            result = {
                'doc_type': 'Kh√¥ng x√°c ƒë·ªãnh',
                'short_code': 'UNKNOWN',
                'confidence': 0.0,
                'reasoning': 'Kh√¥ng th·ªÉ nh·∫≠n di·ªán lo·∫°i t√†i li·ªáu'
            }
        
        # Determine if Cloud Boost is recommended (only for offline engines)
        confidence_threshold = 0.7
        is_cloud = ocr_engine_type in ['google', 'azure']
        recommend_cloud_boost = not is_cloud and result['confidence'] < confidence_threshold
        
        # Add title boost indicator
        title_boost_info = ""
        if result.get('title_boost', False):
            title_boost_info = " [TITLE DETECTED ‚úì]"
        
        response = {
            "success": True,
            "method": "cloud_ocr" if is_cloud else "offline_ocr",
            "ocr_engine": engine_name,
            "original_text": extracted_text,
            "title_text": final_title,  # Use final_title (pattern or OCR)
            "title_extracted_via_pattern": bool(extracted_title),
            "doc_type": result['doc_type'],
            "confidence": result['confidence'],
            "short_code": result['short_code'],
            "reasoning": result.get('reasoning', '') + title_boost_info,
            "recommend_cloud_boost": recommend_cloud_boost,
            "title_boost_applied": result.get('title_boost', False)
        }
        
        # Add cloud-specific fields
        if is_cloud:
            response["ocr_confidence"] = float(ocr_confidence) if ocr_confidence else 0.9
            response["accuracy_estimate"] = "90-96%"
        else:
            # Offline engines
            response["title_text_ocr"] = title_text if 'title_text' in locals() else final_title
            response["avg_font_height"] = round(avg_height, 1) if 'avg_height' in locals() else 0
            response["accuracy_estimate"] = "88-91%" if result.get('title_boost') else "85-88%"
        
        return response
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"‚ùå Error: {error_detail}", file=sys.stderr)
        return {
            "success": False,
            "error": str(e),
            "method": "processing_failed"
        }


def main():
    if len(sys.argv) < 2:
        print(json.dumps({
            "error": "Usage: python process_document.py <file_path> [ocr_engine_type] [cloud_api_key] [cloud_endpoint]",
            "success": False
        }, ensure_ascii=True))
        sys.exit(1)
    
    file_path = sys.argv[1]
    ocr_engine_type = sys.argv[2] if len(sys.argv) > 2 else 'tesseract'
    cloud_api_key = sys.argv[3] if len(sys.argv) > 3 else None
    cloud_endpoint = sys.argv[4] if len(sys.argv) > 4 else None
    
    if not file_path or not os.path.exists(file_path):
        error_msg = json.dumps({
            "error": "File not found or invalid path",
            "success": False
        }, ensure_ascii=False)
        sys.stdout.write(error_msg)
        sys.stdout.write('\n')
        sys.stdout.flush()
        sys.exit(1)
    
    result = process_document(file_path, ocr_engine_type, cloud_api_key, cloud_endpoint)
    
    # Output JSON with ASCII encoding (Unicode will be escaped like \uXXXX)
    # This ensures safe transmission through process pipes
    output = json.dumps(result, ensure_ascii=True, indent=None)
    
    # Write to stdout and flush immediately
    sys.stdout.write(output)
    sys.stdout.write('\n')
    sys.stdout.flush()
    
    sys.exit(0 if result.get('success') else 1)


if __name__ == "__main__":
    main()
