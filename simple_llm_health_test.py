#!/usr/bin/env python3
"""
Simple LLM Health Test - Focus on the specific review request
"""

import requests
import json

def test_llm_health():
    """Test the LLM health endpoint as requested in the review"""
    print("ğŸ” Testing LLM Health Endpoint")
    print("=" * 50)
    
    try:
        # Use the URL from frontend .env
        url = "https://docusmart-vn.preview.emergentagent.com/api/llm/health"
        print(f"Calling: {url}")
        
        response = requests.get(url, timeout=30)
        
        print(f"Status Code: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            
            print("\nğŸ“Š LLM Health Response:")
            print(json.dumps(data, indent=2))
            
            # Extract key information
            status = data.get('status', 'unknown')
            provider = data.get('provider', 'unknown')
            model = data.get('model', 'unknown')
            openai_available = data.get('openai_available', False)
            emergent_available = data.get('emergent_available', False)
            details = data.get('details', 'No details')
            
            print(f"\nğŸ¯ Key Information:")
            print(f"Status: {status}")
            print(f"Provider: {provider}")
            print(f"Model: {model}")
            print(f"OpenAI Available: {openai_available}")
            print(f"Emergent Available: {emergent_available}")
            print(f"Details: {details}")
            
            # Analysis based on review request expectations
            print(f"\nğŸ“‹ Analysis:")
            
            if status == "healthy" and openai_available:
                print("âœ… EXPECTED: OpenAI is working - system is healthy")
                result = "SUCCESS"
            elif status == "degraded" and not openai_available and emergent_available:
                print("âœ… EXPECTED: OpenAI rate-limited, Emergent working - degraded mode")
                result = "SUCCESS"
            elif status == "unhealthy" and not openai_available and not emergent_available:
                print("âŒ BOTH PROVIDERS DOWN: System is unhealthy")
                result = "BOTH_DOWN"
            else:
                print("âš ï¸  UNEXPECTED STATUS COMBINATION")
                result = "UNEXPECTED"
            
            # Check for specific error patterns
            if "429" in details or "Rate limit" in details:
                print("ğŸ“Š Rate limit detected in OpenAI")
            if "401" in details or "unauthorized" in details or "AuthenticationError" in details:
                print("ğŸ”‘ Authentication error detected")
            
            return True, data, result
            
        else:
            print(f"âŒ HTTP Error: {response.status_code}")
            print(f"Response: {response.text}")
            return False, {}, "HTTP_ERROR"
            
    except Exception as e:
        print(f"âŒ Exception: {e}")
        return False, {}, "EXCEPTION"

def main():
    print("ğŸš€ Simple LLM Health Test")
    print("Focus: Re-checking after EMERGENT_LLM_KEY update")
    print("=" * 60)
    
    success, data, result = test_llm_health()
    
    print(f"\n" + "=" * 60)
    print("ğŸ¯ FINAL RESULT")
    print("=" * 60)
    
    if success:
        print("âœ… LLM Health endpoint is accessible")
        print(f"Result: {result}")
        
        if result == "SUCCESS":
            print("ğŸ‰ System is working as expected!")
        elif result == "BOTH_DOWN":
            print("âŒ Both LLM providers are down")
        elif result == "UNEXPECTED":
            print("âš ï¸  Unexpected status combination")
            
        return 0
    else:
        print("âŒ Failed to access LLM Health endpoint")
        return 1

if __name__ == "__main__":
    exit(main())